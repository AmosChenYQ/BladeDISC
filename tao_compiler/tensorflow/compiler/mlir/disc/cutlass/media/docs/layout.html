

<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Layouts and Tensors &mdash; BladeDISC 1.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../../../../_static/css/theme.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../../../_static/css/theme.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../../../_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" /> 

</head>

<body>
    <header>
        <div class="container">
            <a class="site-nav-toggle hidden-lg-up"><i class="icon-menu"></i></a>
            <a class="site-title" href="../../../../../../../../index.html">
                BladeDISC
            </a>
        </div>
    </header>


<div class="breadcrumbs-outer hidden-xs-down">
    <div class="container">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="breadcrumbs">
    
      <li><a href="../../../../../../../../index.html">Docs</a></li>
        
      <li>Layouts and Tensors</li>
    
    
      <li class="breadcrumbs-aside">
        
            
            <a href="../../../../../../../../_sources/tao_compiler/tensorflow/compiler/mlir/disc/cutlass/media/docs/layout.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>
</div>
    </div>
</div>
    <div class="main-outer">
        <div class="container">
            <div class="row">
                <div class="col-12 col-lg-3 site-nav">
                    
<div role="search">
    <form class="search" action="../../../../../../../../search.html" method="get">
        <div class="icon-input">
            <input type="text" name="q" placeholder="Search" />
            <span class="icon-search"></span>
        </div>
        <input type="submit" value="Go" class="d-hidden" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
    </form>
</div>
                    <div class="site-nav-tree">
                        
                            
                            
                                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../README.html">BladeDISC Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#what-s-new">What’s New</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#api-quickview">API QuickView</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#setup-and-examples">Setup and Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#publications">Publications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#tutorials-and-documents-for-developers">Tutorials and Documents for Developers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#presentations-and-talks">Presentations and Talks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#how-to-contribute">How to Contribute</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#building-status">Building Status</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#faq">FAQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../README.html#contact-us">Contact Us</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/install_with_docker.html">Install with Docker</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/install_with_docker.html#download-a-bladedisc-docker-image">Download a BladeDISC Docker Image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/install_with_docker.html#start-a-docker-container">Start a Docker Container</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/build_from_source.html">Build from Source</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/build_from_source.html#prerequisite">Prerequisite</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/build_from_source.html#checkout-the-source">Checkout the Source</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/build_from_source.html#launch-a-development-docker-container">Launch a development Docker container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/build_from_source.html#building-bladedisc-for-tensorflow-users">Building BladeDISC for TensorFlow Users</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/build_from_source.html#building-bladedisc-for-pytorch-users">Building BladeDISC for PyTorch Users</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/quickstart.html">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/quickstart.html#quickstart-for-tensorflow-users">Quickstart for TensorFlow Users</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/quickstart.html#quickstart-for-pytorch-users">Quickstart for PyTorch Users</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/contribution.html">How to Contribute</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/contribution.html#local-development-environment">Local Development Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/contribution.html#submit-a-pull-request-to-bladedisc">Submit a Pull Request to BladeDISC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/tutorials/index.html">Tutorials on Example Use Cases</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/tutorials/tensorflow_inference_and_training.html">Use case of TensorFlow Inference and Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../../../../docs/tutorials/torch_bert_inference.html">Use case of PyTorch Inference</a></li>
</ul>
</li>
</ul>

                            
                        
                    </div>
                </div>
                <div class="col-12 col-lg-9">
                    <div class="document">
                        
                            
  <p><img alt="ALT" src="media/images/gemm-hierarchy-with-epilogue-no-labels.png" /></p>
<p><a class="reference external" href="/README.md#documentation">README</a> &gt; <strong>Layouts and Tensors</strong></p>
<section id="layouts-and-tensors">
<h1>Layouts and Tensors<a class="headerlink" href="#layouts-and-tensors" title="Permalink to this heading">¶</a></h1>
<p><em>Tensors</em> are mathematical objects represented by a multidimensional array of numeric elements in memory.
These may define two dimensional matrices upon which classical linear algebra computations may be defined or
higher dimensional objects frequently used to structure data used by Deep Learning applications and frameworks.</p>
<p>This document describes design patterns used in CUTLASS to map logical index spaces onto memory (Layouts) and to
indirectly reference tensors in memory (TensorRef and TensorView objects).</p>
<p>As described, CUTLASS adheres to the following terminology which is consistent with the C++ Standard Library.</p>
<ul class="simple">
<li><p><em>size</em> (scalar): number of elements in a tensor</p></li>
<li><p><em>capacity</em> (scalar): number of elements needed to represent tensor in memory (may be larger than <em>size</em>)</p></li>
<li><p><em>rank</em> (scalar): number of logical dimensions describing tensor</p></li>
<li><p><em>extent</em> (vector): size of each logical dimension in a tensor</p></li>
</ul>
<section id="cutlass-layout-concept">
<h2>CUTLASS Layout Concept<a class="headerlink" href="#cutlass-layout-concept" title="Permalink to this heading">¶</a></h2>
<p>CUTLASS Layouts are a systematic design pattern for the following:</p>
<ul class="simple">
<li><p>Mapping <em>logical</em> index space to <em>physical</em> offsets in memory</p></li>
<li><p>Storing the dynamic state needed in the above computation</p></li>
<li><p>Defining a type system for partial specialization of other CUTLASS components</p></li>
</ul>
<p><em>Concept:</em> layouts satisfy the following concept.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">/// CUTLASS Layout concept example</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">LayoutConcept</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Logical rank of tensor</span>
<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">kRank</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Rank of stride vector</span>
<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">kStrideRank</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Index type used for coordinates</span>
<span class="w">  </span><span class="k">struct</span><span class="w"> </span><span class="nc">Index</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Long index type used for offsets</span>
<span class="w">  </span><span class="k">struct</span><span class="w"> </span><span class="nc">LongIndex</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Logical coordinate - satisfies Coord&lt;kRank, ..&gt;</span>
<span class="w">  </span><span class="k">struct</span><span class="w"> </span><span class="nc">TensorCoord</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Stride object - satisfies Coord&lt;kStrideRank, ..&gt;</span>
<span class="w">  </span><span class="k">struct</span><span class="w"> </span><span class="nc">Stride</span><span class="w"></span>

<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// Methods</span>
<span class="w">  </span><span class="c1">//</span>

<span class="w">  </span><span class="c1">/// Constructor</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="nf">LayoutConcept</span><span class="p">();</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Ctor</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="nf">LayoutConcept</span><span class="p">(</span><span class="n">Stride</span><span class="w"> </span><span class="n">stride</span><span class="p">);</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Helper returns a layout to a tightly packed tensor</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">LayoutConcept</span><span class="w"> </span><span class="n">packed</span><span class="p">(</span><span class="n">TensorCoord</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="n">extent</span><span class="p">);</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Function call operator returns the offset of a coordinate in linear memory. </span>
<span class="w">  </span><span class="c1">/// Assumes coordinate has convention (row, column)</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="n">LongIndex</span><span class="w"> </span><span class="k">operator</span><span class="p">()(</span><span class="n">TensorCoord</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="n">coord</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Inverse of layout function, mapping linear offset to logical coordinate</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="n">TensorCoord</span><span class="w"> </span><span class="n">inverse</span><span class="p">(</span><span class="n">LongIndex</span><span class="w"> </span><span class="n">offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Returns the stride of the layout</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="n">Stride</span><span class="w"> </span><span class="n">stride</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Returns the stride of the layout</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="n">Stride</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">stride</span><span class="p">();</span><span class="w"></span>

<span class="w">  </span><span class="c1">/// Compute the number of contiguous elements needed to store a tensor with the given size</span>
<span class="w">  </span><span class="n">CUTLASS_HOST_DEVICE</span><span class="w"></span>
<span class="w">  </span><span class="n">LongIndex</span><span class="w"> </span><span class="n">capacity</span><span class="p">(</span><span class="n">TensorCoord</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="n">extent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<p><em>Layout</em> objects generalize leading dimensions of matrices typical in <em>BLAS</em> implementations. For example, cuBLAS assumes
Fortran-style <em>column-major</em> layouts of matrices and refers to this as the matrix’s “leading dimension.”</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">cublasGemmEx</span><span class="p">(</span><span class="w"></span>
<span class="w">  </span><span class="p">...</span><span class="w"></span>
<span class="w">  </span><span class="n">ptr_A</span><span class="p">,</span><span class="w">      </span><span class="c1">// pointer to first element of matrix A</span>
<span class="w">  </span><span class="n">lda</span><span class="p">,</span><span class="w">        </span><span class="c1">// leading dimension</span>
<span class="w">  </span><span class="p">...</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>This implies an element at coordinate (<em>row</em>, <em>column</em>) has offset <code class="docutils literal notranslate"><span class="pre">row</span> <span class="pre">+</span> <span class="pre">lda</span> <span class="pre">*</span> <span class="pre">column</span></code>.</p>
<p>This is equivalently represented by CUTLASS’s <code class="docutils literal notranslate"><span class="pre">layout::ColumnMajor</span></code> type as follows.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="w"> </span><span class="nf">layout</span><span class="p">(</span><span class="n">lda</span><span class="p">);</span><span class="w"> </span>

<span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layout</span><span class="p">({</span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">column</span><span class="p">});</span><span class="w">     </span><span class="c1">// returns row  + lda * column</span>
</pre></div>
</div>
<p>Other layout functions are possible such as row-major:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">layout</span><span class="o">::</span><span class="n">RowMajor</span><span class="w"> </span><span class="nf">layout</span><span class="p">(</span><span class="n">lda</span><span class="p">);</span><span class="w"> </span>

<span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layout</span><span class="p">({</span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">column</span><span class="p">});</span><span class="w">     </span><span class="c1">// returns lda * row + column</span>
</pre></div>
</div>
<p>In both cases, the <em>logical</em> coordinate (<em>row</em>, <em>column</em>) is represented by the same object. This enables an algorithm to be
implemented as generic template, with locations within tensors always specified in logical space. <em>Layout</em> objects map this to
physical offsets in memory.</p>
<p>The layout’s <code class="docutils literal notranslate"><span class="pre">::packed()</span></code> static method may be used to construct a layout object given the extent of a densely packed tensor.
This method is needed when an algorithm must define a buffer of arbitrary layout.</p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">typename</span><span class="w"> </span><span class="nc">ArbitraryLayout</span><span class="o">::</span><span class="n">TensorCoord</span><span class="w"> </span><span class="n">extent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_Coord</span><span class="p">(...);</span><span class="w"></span>
<span class="k">typename</span><span class="w"> </span><span class="nc">ArbitraryLayout</span><span class="o">::</span><span class="n">TensorCoord</span><span class="w"> </span><span class="n">coord</span><span class="p">;</span><span class="w"></span>

<span class="n">ArbitraryLayout</span><span class="w"> </span><span class="n">layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ArbitraryLayout</span><span class="o">::</span><span class="n">packed</span><span class="p">(</span><span class="n">extent</span><span class="p">);</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layout</span><span class="p">({</span><span class="n">coord</span><span class="p">});</span><span class="w"></span>
</pre></div>
</div>
<p>The layout’s <code class="docutils literal notranslate"><span class="pre">::capacity()</span></code> method computes the number of locations in memory needed to represent a tensor. This is
useful when allocating memory, as more storage may be needed than what is strictly necessary for a fully packed
tensor.</p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">lda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">columns</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">padding</span><span class="p">;</span><span class="w"></span>
<span class="n">MatrixCoord</span><span class="w"> </span><span class="n">extent</span><span class="p">{</span><span class="n">rows</span><span class="p">,</span><span class="w"> </span><span class="n">columns</span><span class="p">};</span><span class="w"></span>

<span class="n">layout</span><span class="o">::</span><span class="n">RowMajor</span><span class="w"> </span><span class="nf">layout</span><span class="p">(</span><span class="n">lda</span><span class="p">);</span><span class="w"></span>

<span class="k">auto</span><span class="w"> </span><span class="n">capacity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layout</span><span class="p">.</span><span class="n">capacity</span><span class="p">(</span><span class="n">extent</span><span class="p">);</span><span class="w">    </span><span class="c1">// returns rows * (columns + padding) </span>
</pre></div>
</div>
</section>
<section id="accessing-elements-within-a-tensor">
<h2>Accessing elements within a tensor<a class="headerlink" href="#accessing-elements-within-a-tensor" title="Permalink to this heading">¶</a></h2>
<section id="tensorref">
<h3>TensorRef<a class="headerlink" href="#tensorref" title="Permalink to this heading">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">TensorRef&lt;class</span> <span class="pre">T,</span> <span class="pre">class</span> <span class="pre">Layout&gt;</span></code> is a structure containing both a pointer to the start of a
tensor and a layout object to access its elements. This is a convenient object which may be
passed to functions to limit an explosion of arguments when the number of stride elements is
numerous.</p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">int4_t</span><span class="w"> </span><span class="o">*</span><span class="n">ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>
<span class="kt">int</span><span class="w"> </span><span class="n">ldm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>
<span class="kt">int</span><span class="w"> </span><span class="n">column</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>

<span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="w"> </span><span class="nf">layout</span><span class="p">(</span><span class="n">ldm</span><span class="p">);</span><span class="w"></span>
<span class="n">TensorRef</span><span class="o">&lt;</span><span class="n">int4_t</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">ref</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">);</span><span class="w"></span>

<span class="n">int4_t</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ref</span><span class="p">.</span><span class="n">at</span><span class="p">({</span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">column</span><span class="p">});</span><span class="w">     </span><span class="c1">// loads a 4-bit signed integer from the tensor</span>

<span class="n">ref</span><span class="p">.</span><span class="n">at</span><span class="p">({</span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">column</span><span class="p">})</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="n">_s4</span><span class="p">;</span><span class="w">     </span><span class="c1">// transforms this quantity and stores it back</span>
</pre></div>
</div>
</section>
<section id="tensorview">
<h3>TensorView<a class="headerlink" href="#tensorview" title="Permalink to this heading">¶</a></h3>
<p>Matrices and tensors used in linear algebra computations are invariably finite. <code class="docutils literal notranslate"><span class="pre">TensorView&lt;class</span> <span class="pre">T,</span> <span class="pre">class</span> <span class="pre">Layout&gt;</span></code> extends <code class="docutils literal notranslate"><span class="pre">TensorRef&lt;&gt;</span></code> by
adding an <code class="docutils literal notranslate"><span class="pre">extent</span></code> vector to describe the logical extent of the tensor or matrix.</p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">int4_t</span><span class="w"> </span><span class="o">*</span><span class="n">ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>
<span class="kt">int</span><span class="w"> </span><span class="n">ldm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>
<span class="n">MatrixCoord</span><span class="w"> </span><span class="n">extent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>
<span class="kt">int</span><span class="w"> </span><span class="n">column</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"></span>

<span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="w"> </span><span class="nf">layout</span><span class="p">(</span><span class="n">ldm</span><span class="p">);</span><span class="w"></span>
<span class="n">TensorView</span><span class="o">&lt;</span><span class="n">int4_t</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">view</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">extent</span><span class="p">);</span><span class="w"></span>

<span class="n">MatrixCoord</span><span class="w"> </span><span class="n">coord</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">column</span><span class="p">};</span><span class="w"></span>

<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">view</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="n">coord</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">     </span><span class="c1">// verify coordinate is in bounds before performing access</span>
<span class="w">  </span>
<span class="w">  </span><span class="n">int4_t</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ref</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">coord</span><span class="p">);</span><span class="w">  </span>
<span class="w">  </span><span class="n">ref</span><span class="p">.</span><span class="n">at</span><span class="p">({</span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">column</span><span class="p">})</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="n">_s4</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>A <code class="docutils literal notranslate"><span class="pre">TensorView&lt;&gt;</span></code> may be constructed from a <code class="docutils literal notranslate"><span class="pre">TensorRef&lt;&gt;</span></code> succinctly as follows:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="w"> </span><span class="nf">layout</span><span class="p">(</span><span class="n">ldm</span><span class="p">);</span><span class="w"></span>
<span class="n">TensorRef</span><span class="o">&lt;</span><span class="n">int4_t</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">ref</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">);</span><span class="w"></span>

<span class="n">TensorView</span><span class="o">&lt;</span><span class="n">int4_t</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">::</span><span class="n">ColumnMajor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">view</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span><span class="w"> </span><span class="n">extent</span><span class="p">);</span><span class="w">    </span><span class="c1">// construct TensorView from TensorRef and extent</span>
</pre></div>
</div>
<p>Note, computations avoid becoming overdetermined by accepting a single problem size component
and <code class="docutils literal notranslate"><span class="pre">TensorRef</span></code> objects for each of the operands whose extents are implied as a precondition of the operation. By avoiding
redundant storage of extent quantities, CUTLASS minimizes capacity utilization of precious resources such as constant memory.
This is consistent with BLAS conventions.</p>
</section>
</section>
</section>
<section id="summary">
<h1>Summary:<a class="headerlink" href="#summary" title="Permalink to this heading">¶</a></h1>
<p>The design patterns described in this document form a hierarchy:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">*ptr;</span></code> is a pointer to a contiguous sequence of elements of type <code class="docutils literal notranslate"><span class="pre">T</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Layout</span> <span class="pre">layout;</span></code> is an object mapping an index space to a linear offset</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TensorRef&lt;T,</span> <span class="pre">Layout&gt;</span> <span class="pre">ref(ptr,</span> <span class="pre">layout);</span></code> is an object pointing to an <em>unbounded</em> tensor containing elements of type <code class="docutils literal notranslate"><span class="pre">T</span></code> and a layout of type <code class="docutils literal notranslate"><span class="pre">Layout</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TensorView&lt;T,</span> <span class="pre">Layout&gt;</span> <span class="pre">view(ref,</span> <span class="pre">extent);</span></code> is an object pointing to a <em>bounded</em> tensor containing elements of type <code class="docutils literal notranslate"><span class="pre">T</span></code> and a layout of type <code class="docutils literal notranslate"><span class="pre">Layout</span></code></p></li>
</ul>
</section>
<section id="appendix-existing-layouts">
<h1>Appendix: Existing Layouts<a class="headerlink" href="#appendix-existing-layouts" title="Permalink to this heading">¶</a></h1>
<p>This section enumerates several existing Layout types defined in CUTLASS.</p>
<p>Matrix layouts:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">PitchLinear</span></code>: data layout defined by <em>contiguous</em> and <em>strided</em> dimensions. <em>contiguous</em> refers to consecutive elements in memory, where as <em>strided</em> refers to data separated by a uniform stride
– Rank: 2
– TensorCoord type: <code class="docutils literal notranslate"><span class="pre">PitchLinearCoord</span></code>
– Shape type: <code class="docutils literal notranslate"><span class="pre">PitchLinearShape</span></code>
– Stride rank: 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ColumnMajor</span></code>: data layout defined by <em>rows</em> and <em>columns</em> dimensions. Can be mapped to <code class="docutils literal notranslate"><span class="pre">PitchLinear</span></code> by: (<em>contiguous</em> = <em>rows</em>, <em>strided</em> = <em>columns</em>)
– Rank: 2
– TensorCoord type: <code class="docutils literal notranslate"><span class="pre">MatrixCoord</span></code>
– Shape type: <code class="docutils literal notranslate"><span class="pre">MatrixShape</span></code>
– Stride rank: 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RowMajor</span></code>: data layout defined by <em>rows</em> and <em>columns</em> dimensions. Can be mapped to <code class="docutils literal notranslate"><span class="pre">PitchLinear</span></code> by: (<em>contiguous</em> = <em>columns</em>, <em>strided</em> = <em>rows</em>)
– Rank: 2
– TensorCoord type: <code class="docutils literal notranslate"><span class="pre">MatrixCoord</span></code>
– Shape type: <code class="docutils literal notranslate"><span class="pre">MatrixShape</span></code>
– Stride rank: 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ColumnMajorInterleaved&lt;k&gt;</span></code>: data layout defined by <em>rows</em> and <em>columns</em> dimensions. Data is packed into a ‘column-major’ arrangement of row vectors of fixed length.
– Rank: 2
– TensorCoord type: <code class="docutils literal notranslate"><span class="pre">MatrixCoord</span></code>
– Shape type: <code class="docutils literal notranslate"><span class="pre">MatrixShape</span></code>
– Stride rank: 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RowMajorInterleaved&lt;k&gt;</span></code>: data layout defined by <em>rows</em> and <em>columns</em> dimensions. Data is packed into a ‘row-major’ arrangement of column vectors of fixed length.
– Rank: 2
– TensorCoord type: <code class="docutils literal notranslate"><span class="pre">MatrixCoord</span></code>
– Shape type: <code class="docutils literal notranslate"><span class="pre">MatrixShape</span></code>
– Stride rank: 1</p></li>
</ul>
<p>Tensor layouts:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">TensorNHWC</span></code>:</p></li>
</ul>
<p>Permuted Shared Memory Layouts:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">TensorOpCongruous&lt;ElementSize&gt;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TensorOpCrosswise&lt;ElementSize&gt;</span></code></p></li>
</ul>
</section>
<section id="copyright">
<h1>Copyright<a class="headerlink" href="#copyright" title="Permalink to this heading">¶</a></h1>
<p>Copyright (c) 2017 - 2022 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: BSD-3-Clause</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="n">Redistribution</span> <span class="ow">and</span> <span class="n">use</span> <span class="ow">in</span> <span class="n">source</span> <span class="ow">and</span> <span class="n">binary</span> <span class="n">forms</span><span class="p">,</span> <span class="k">with</span> <span class="ow">or</span> <span class="n">without</span>
  <span class="n">modification</span><span class="p">,</span> <span class="n">are</span> <span class="n">permitted</span> <span class="n">provided</span> <span class="n">that</span> <span class="n">the</span> <span class="n">following</span> <span class="n">conditions</span> <span class="n">are</span> <span class="n">met</span><span class="p">:</span>

  <span class="mf">1.</span> <span class="n">Redistributions</span> <span class="n">of</span> <span class="n">source</span> <span class="n">code</span> <span class="n">must</span> <span class="n">retain</span> <span class="n">the</span> <span class="n">above</span> <span class="n">copyright</span> <span class="n">notice</span><span class="p">,</span> <span class="n">this</span>
  <span class="nb">list</span> <span class="n">of</span> <span class="n">conditions</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">following</span> <span class="n">disclaimer</span><span class="o">.</span>

  <span class="mf">2.</span> <span class="n">Redistributions</span> <span class="ow">in</span> <span class="n">binary</span> <span class="n">form</span> <span class="n">must</span> <span class="n">reproduce</span> <span class="n">the</span> <span class="n">above</span> <span class="n">copyright</span> <span class="n">notice</span><span class="p">,</span>
  <span class="n">this</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">conditions</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">following</span> <span class="n">disclaimer</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">documentation</span>
  <span class="ow">and</span><span class="o">/</span><span class="ow">or</span> <span class="n">other</span> <span class="n">materials</span> <span class="n">provided</span> <span class="k">with</span> <span class="n">the</span> <span class="n">distribution</span><span class="o">.</span>

  <span class="mf">3.</span> <span class="n">Neither</span> <span class="n">the</span> <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">copyright</span> <span class="n">holder</span> <span class="n">nor</span> <span class="n">the</span> <span class="n">names</span> <span class="n">of</span> <span class="n">its</span>
  <span class="n">contributors</span> <span class="n">may</span> <span class="n">be</span> <span class="n">used</span> <span class="n">to</span> <span class="n">endorse</span> <span class="ow">or</span> <span class="n">promote</span> <span class="n">products</span> <span class="n">derived</span> <span class="kn">from</span>
  <span class="nn">this</span> <span class="n">software</span> <span class="n">without</span> <span class="n">specific</span> <span class="n">prior</span> <span class="n">written</span> <span class="n">permission</span><span class="o">.</span>

  <span class="n">THIS</span> <span class="n">SOFTWARE</span> <span class="n">IS</span> <span class="n">PROVIDED</span> <span class="n">BY</span> <span class="n">THE</span> <span class="n">COPYRIGHT</span> <span class="n">HOLDERS</span> <span class="n">AND</span> <span class="n">CONTRIBUTORS</span> <span class="s2">&quot;AS IS&quot;</span>
  <span class="n">AND</span> <span class="n">ANY</span> <span class="n">EXPRESS</span> <span class="n">OR</span> <span class="n">IMPLIED</span> <span class="n">WARRANTIES</span><span class="p">,</span> <span class="n">INCLUDING</span><span class="p">,</span> <span class="n">BUT</span> <span class="n">NOT</span> <span class="n">LIMITED</span> <span class="n">TO</span><span class="p">,</span> <span class="n">THE</span>
  <span class="n">IMPLIED</span> <span class="n">WARRANTIES</span> <span class="n">OF</span> <span class="n">MERCHANTABILITY</span> <span class="n">AND</span> <span class="n">FITNESS</span> <span class="n">FOR</span> <span class="n">A</span> <span class="n">PARTICULAR</span> <span class="n">PURPOSE</span> <span class="n">ARE</span>
  <span class="n">DISCLAIMED</span><span class="o">.</span> <span class="n">IN</span> <span class="n">NO</span> <span class="n">EVENT</span> <span class="n">SHALL</span> <span class="n">THE</span> <span class="n">COPYRIGHT</span> <span class="n">HOLDER</span> <span class="n">OR</span> <span class="n">CONTRIBUTORS</span> <span class="n">BE</span> <span class="n">LIABLE</span>
  <span class="n">FOR</span> <span class="n">ANY</span> <span class="n">DIRECT</span><span class="p">,</span> <span class="n">INDIRECT</span><span class="p">,</span> <span class="n">INCIDENTAL</span><span class="p">,</span> <span class="n">SPECIAL</span><span class="p">,</span> <span class="n">EXEMPLARY</span><span class="p">,</span> <span class="n">OR</span> <span class="n">CONSEQUENTIAL</span>
  <span class="n">DAMAGES</span> <span class="p">(</span><span class="n">INCLUDING</span><span class="p">,</span> <span class="n">BUT</span> <span class="n">NOT</span> <span class="n">LIMITED</span> <span class="n">TO</span><span class="p">,</span> <span class="n">PROCUREMENT</span> <span class="n">OF</span> <span class="n">SUBSTITUTE</span> <span class="n">GOODS</span> <span class="n">OR</span>
  <span class="n">SERVICES</span><span class="p">;</span> <span class="n">LOSS</span> <span class="n">OF</span> <span class="n">USE</span><span class="p">,</span> <span class="n">DATA</span><span class="p">,</span> <span class="n">OR</span> <span class="n">PROFITS</span><span class="p">;</span> <span class="n">OR</span> <span class="n">BUSINESS</span> <span class="n">INTERRUPTION</span><span class="p">)</span> <span class="n">HOWEVER</span>
  <span class="n">CAUSED</span> <span class="n">AND</span> <span class="n">ON</span> <span class="n">ANY</span> <span class="n">THEORY</span> <span class="n">OF</span> <span class="n">LIABILITY</span><span class="p">,</span> <span class="n">WHETHER</span> <span class="n">IN</span> <span class="n">CONTRACT</span><span class="p">,</span> <span class="n">STRICT</span> <span class="n">LIABILITY</span><span class="p">,</span>
  <span class="n">OR</span> <span class="n">TORT</span> <span class="p">(</span><span class="n">INCLUDING</span> <span class="n">NEGLIGENCE</span> <span class="n">OR</span> <span class="n">OTHERWISE</span><span class="p">)</span> <span class="n">ARISING</span> <span class="n">IN</span> <span class="n">ANY</span> <span class="n">WAY</span> <span class="n">OUT</span> <span class="n">OF</span> <span class="n">THE</span> <span class="n">USE</span>
  <span class="n">OF</span> <span class="n">THIS</span> <span class="n">SOFTWARE</span><span class="p">,</span> <span class="n">EVEN</span> <span class="n">IF</span> <span class="n">ADVISED</span> <span class="n">OF</span> <span class="n">THE</span> <span class="n">POSSIBILITY</span> <span class="n">OF</span> <span class="n">SUCH</span> <span class="n">DAMAGE</span><span class="o">.</span>
</pre></div>
</div>
</section>


                        
                    </div>
                </div>
            </div>
        </div>
    </div>    


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../../../../../',
            VERSION:'1.0.0',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
    <script type="text/javascript" src="../../../../../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/sphinx_highlight.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/clipboard.min.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/copybutton.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script type="text/javascript" src="../../../../../../../../_static/js/theme.js"></script>
  
    <div class="footer" role="contentinfo">
        <div class="container">
            &#169; Copyright bladedisc-dev@list.alibaba-inc.com.
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.
        </div>
    </div>  

</body>
</html>